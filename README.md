Here is the list of ML study and portfolio  projects that I have uploaded (in progress):

Portfolio:
1. [Decision Trees and Random Forest Project.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Decision%20Trees%20and%20Random%20Forest%20Project.ipynb)

   Results: we analysed real financial data to see whether or not our model would be able to correctly predict if the loan would be returned in full. Visualisation included some histograms, jointplot, and countplot. We also converted a categorical variable. First, we trained one decision tree; next, a random forest model. Randm Forest performed (as expected) significantly better, with a very low level of Type I error.

2. [Logistic Regression with Python Project.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Logistic%20Regression%20with%20Python%20Project.ipynb)
   
   Results: I used Logistic Regression to predict the class of a passenger on the Titanic - Survived or Deceased. Missing age values were imputed by using the mean age for the passenger class. I got satisfactory results which could be further improved by applying other ML models or working on a "Name" feature.

Study projects:
1. [Small Logistic Regression Project.ipynb ](https://github.com/IulliaK/Machine-Learning/blob/main/Small%20Logistic%20Regression%20Project.ipynb) on a fake data 

   Results: received quite good results - confusion matrix shows that mostly all were classified correctly. I used histogram and pairplot to visualise data.

2. [Decision Trees and Random Forests in Python.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Decision%20Trees%20and%20Random%20Forests%20in%20Python.ipynb)

   Result: in this notebook, we worked with a small kythosis dataset to compare the application of a single decision tree and a random forest. Because the data is highly imbalanced (most observations note the absence of the disease after the operation), the difference isn't striking but still we proved that Random Forect performs better (5 missclassified observations instead of 8 for a Decision Tree).

3. [Support Vector Machines with Python.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Support%20Vector%20Machines%20with%20Python.ipynb)
   
   Result: in this work, I took a built-in dataset - breast_cancer, and applied SVM to classify a tumor as malignant or bening. SVM got very good results - about 0.93, which was further enhanced with GridSearch, up to 0.94. To decide which model to use - with or without GreedSearch, a domain knowledge is required.

4. [Support Vector Machines Study Project.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Support%20Vector%20Machines%20Study%20Project.ipynb)

   Result: in this study notebook, I used a small iris dataset to showcase how SVM and GridSearch work. Because of the very small number of observations in the dataset, even without the GridSearch the results were almost perfect.

5. [Linear Regression with Python.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Linear%20Regression%20with%20Python.ipynb)
   
   Result: we took a fake dataset to predict house prices based on some features. Since it is not real data, we cannot make serious conclusions. We did, however, showed the application of Linear Regression model and used three regression evaluation metrics - MAE, MSE, and RMSE. We also plotted residuals (they have normal distribution).

7. [Linear Regression Project.ipynb](https://github.com/IulliaK/Machine-Learning/blob/main/Linear%20Regression%20Project.ipynb)
   
   Result: we took a fake e-commerce dataset and analysed numerical variables to find out what influences the most our target variable - Yearly Amount Spent. We found out that one unit increase in length of membership leads to 61$ increase in spendings. We also found out that the company should focus more on their app rather than their website, since app brings more profit. We used jointplots and a pairplot to visualise findings. Linear Regression was applied to predict Yearly Amount Spent, and the following metrics were used to evaluate performance: MAE, MSE, RMSE, R Squared. R Suared is 0.99 - due to the the fact that data is artificial. We also plotted residuals to make sure they have approximately normal distribution.
   

